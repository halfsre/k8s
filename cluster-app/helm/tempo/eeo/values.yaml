global:
  image:
    registry: docker.io
  clusterDomain: 'cluster.local'
  dnsService: 'coredns'
  dnsNamespace: 'kube-system'

reportingEnabled: false

tempo:
  image:
    registry: docker.io
    repository: grafana/tempo
    tag: 2.2.3
    pullPolicy: IfNotPresent

ingester:
  replicas: 5
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 60
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  resources:
    requests:
      memory: "8Gi"
      cpu: "500m"
    limits:
      memory: "16Gi"
      cpu: "1000m"
  terminationGracePeriodSeconds: 300
  extraVolumeMounts: []
  extraVolumes: []
  persistence:
    enabled: true
    inMemory: false
    storageClass: "csi-disk-topology"
    size: 10Gi
  config:
    replication_factor: 1
    trace_idle_period: 10s
    flush_check_period: 10s
    max_block_bytes: 209715200
    max_block_duration: 1m
    complete_block_timeout: 15m

metricsGenerator:
  enabled: false
  annotations: {}
  replicas: 1
  ports:
    - name: grpc
      port: 9095
      service: true
    - name: http-metrics
      port: 3100
      service: true
  config:
    registry:
      collection_interval: 15s
      external_labels: {}
      stale_duration: 15m
    processor:
      service_graphs:
        dimensions: []
        histogram_buckets: [0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8]
        max_items: 10000
        wait: 10s
        workers: 10
      span_metrics:
        dimensions: []
        histogram_buckets: [0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512, 1.02, 2.05, 4.10]
    storage:
      path: /var/tempo/wal
      wal:
      remote_write_flush_deadline: 1m
      remote_write: []

distributor:
  replicas: 3
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 80
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  resources:
    requests:
      memory: "1024Mi"
      cpu: "250m"
    limits:
      memory: "2048Mi"
      cpu: "1000m"
  terminationGracePeriodSeconds: 30
  extraVolumeMounts: []
  extraVolumes: []
  config:
    log_received_traces: null
    log_received_spans:
      enabled: false
      include_all_attributes: false
      filter_by_status_error: false
    extend_writes: null
compactor:
  replicas: 3
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "8Gi"
      cpu: "4000m"
  terminationGracePeriodSeconds: 30
  nodeSelector: {}
  tolerations: []
  extraVolumeMounts: []
  extraVolumes: []
  config:
    compaction:
      block_retention: 192h
      compacted_block_retention: 30m
      compaction_window: 30m
      v2_in_buffer_bytes: 5242880
      v2_out_buffer_bytes: 20971520
      max_compaction_objects: 6000000
      max_block_bytes: 107374182400
      retention_concurrency: 10
      v2_prefetch_traces_count: 1000
      max_time_per_tenant: 5m
      compaction_cycle: 30s
  service:
    annotations: {}
  dnsConfigOverides:
    enabled: false
    dnsConfig:
      options:
        - name: ndots

querier:
  replicas: 2
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 2
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage:
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  resources:
    requests:
      memory: "2Gi"
      cpu: "250m"
    limits:
      memory: "8Gi"
      cpu: "4000m"
  terminationGracePeriodSeconds: 30
  affinity: |
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              {{- include "tempo.selectorLabels" (dict "ctx" . "component" "querier" "etcd" true) | nindent 10 }}
          topologyKey: kubernetes.io/hostname
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                {{- include "tempo.selectorLabels" (dict "ctx" . "component" "querier" "etcd" true) | nindent 12 }}
            topologyKey: failure-domain.beta.kubernetes.io/zone
  nodeSelector: {}
  tolerations: []
  extraVolumeMounts: []
  extraVolumes: []
  config:
    frontend_worker:
      grpc_client_config:
        max_send_msg_size: 16777216
    trace_by_id:
      query_timeout: 10s
    search:
      external_endpoints: []
      query_timeout: 30s
      prefer_self: 10
      external_hedge_requests_at: 8s
      external_hedge_requests_up_to: 2
    max_concurrent_queries: 20

  service:
    annotations: {}
  appProtocol:
    grpc: null

queryFrontend:
  query:
    enabled: false
#    image:
#      registry: null
#      pullSecrets: []
#      repository: grafana/tempo-query
#      tag: 2.1.1
    resources:
      requests:
        memory: "400Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    extraArgs: []
    extraEnv: []
    extraEnvFrom: []
    extraVolumeMounts: []
    extraVolumes: []
    config: |
      backend: 127.0.0.1:3100
  replicas: 2
  config:
    max_retries: 2
    search:
      concurrent_jobs: 1000
      target_bytes_per_job: 104857600
    trace_by_id:
      query_shards: 50
      hedge_requests_at: 2s
      hedge_requests_up_to: 2
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
  service:
    port: 16686
    annotations: {}
    type: ClusterIP
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
  serviceDiscovery:
    annotations: {}
  ingress:
    enabled: false
    annotations: {}
    hosts:
      - host: query.tempo.example.com
        paths:
          - path: /
    tls:
      - secretName: tempo-query-tls
        hosts:
          - query.tempo.example.com
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  resources: {}
  terminationGracePeriodSeconds: 30
  extraVolumeMounts: []
  extraVolumes: []

multitenancyEnabled: false

traces:
  otlp:
    http:
      enabled: true
      receiverConfig: {}
    grpc:
      enabled: true
      receiverConfig: {}


config: |
  multitenancy_enabled: {{ .Values.multitenancyEnabled }}

  usage_report:
    reporting_enabled: {{ .Values.reportingEnabled }}

  {{- if .Values.enterprise.enabled }}
  license:
    path: "/license/license.jwt"

  admin_api:
    leader_election:
      enabled: true
      ring:
        kvstore:
          store: "etcd"

  auth:
    type: enterprise

  http_api_prefix: {{get .Values.tempo.structuredConfig "http_api_prefix"}}

  admin_client:
    storage:
      backend: {{.Values.storage.admin.backend}}
      {{- if eq .Values.storage.admin.backend "s3"}}
      s3:
        {{- toYaml .Values.storage.admin.s3 | nindent 6}}
      {{- end}}
  {{- end }}

  {{- if and .Values.enterprise.enabled .Values.enterpriseGateway.useDefaultProxyURLs }}
  gateway:
    proxy:
      admin_api:
        url: http://{{ template "tempo.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      compactor:
        url: http://{{ template "tempo.fullname" . }}-compactor.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      default:
        url: http://{{ template "tempo.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      distributor:
        url: http://{{ template "tempo.fullname" . }}-distributor.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      distributor_ingest:
        url: h2c://{{ template "tempo.fullname" . }}-distributor.{{ .Release.Namespace }}.svc:4317
      ingester:
        url: http://{{ template "tempo.fullname" . }}-ingester.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      querier:
        url: http://{{ template "tempo.fullname" . }}-querier.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}
      query_frontend:
        url: http://{{ template "tempo.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc:{{ include "tempo.serverHttpListenPort" . }}{{get .Values.tempo.structuredConfig "http_api_prefix"}}
  {{- end }}

  compactor:
    compaction:
      block_retention: {{ .Values.compactor.config.compaction.block_retention }}
      compacted_block_retention: {{ .Values.compactor.config.compaction.compacted_block_retention }}
      compaction_window: {{ .Values.compactor.config.compaction.compaction_window }}
      v2_in_buffer_bytes: {{ .Values.compactor.config.compaction.v2_in_buffer_bytes }}
      v2_out_buffer_bytes: {{ .Values.compactor.config.compaction.v2_out_buffer_bytes }}
      max_compaction_objects: {{ .Values.compactor.config.compaction.max_compaction_objects }}
      max_block_bytes: {{ .Values.compactor.config.compaction.max_block_bytes }}
      retention_concurrency: {{ .Values.compactor.config.compaction.retention_concurrency }}
      v2_prefetch_traces_count: {{ .Values.compactor.config.compaction.v2_prefetch_traces_count }}
      max_time_per_tenant: {{ .Values.compactor.config.compaction.max_time_per_tenant }}
      compaction_cycle: {{ .Values.compactor.config.compaction.compaction_cycle }}
    ring:
      kvstore:
        store: etcd
        prefix: tempo-compactor/
        etcd:
          endpoints: [loki-etcd.loki.svc.cluster.local:2379]
          dial_timeout: 10s
          max_retries: 10
          tls_enabled: false
          tls_cert_path: ""
          username: "root"
          password: "BigESi7UYRbG41DG"
  {{- if .Values.metricsGenerator.enabled }}
  metrics_generator:
    ring:
      kvstore:
        store: etcd
        prefix: tempo-metrics/
        etcd:
          endpoints: [loki-etcd.loki.svc.cluster.local:2379]
          dial_timeout: 10s
          max_retries: 10
          tls_enabled: false
          tls_cert_path: ""
          username: "root"
          password: "BigESi7UYRbG41DG"
    processor:
      {{- toYaml .Values.metricsGenerator.config.processor | nindent 6 }}
    storage:
      {{- toYaml .Values.metricsGenerator.config.storage | nindent 6 }}
    registry:
      {{- toYaml .Values.metricsGenerator.config.registry | nindent 6 }}
  {{- end }}
  distributor:
    ring:
      kvstore:
        store: etcd
        etcd:
          endpoints: [loki-etcd.loki.svc.cluster.local:2379]
          dial_timeout: 10s
          max_retries: 5
          tls_enabled: false
          username: "root"
          password: "BigESi7UYRbG41DG"
    receivers:
      {{- if  or (.Values.traces.jaeger.thriftCompact.enabled) (.Values.traces.jaeger.thriftBinary.enabled) (.Values.traces.jaeger.thriftHttp.enabled) (.Values.traces.jaeger.grpc.enabled) }}
      jaeger:
        protocols:
          {{- if .Values.traces.jaeger.thriftCompact.enabled }}
          thrift_compact:
            {{- $mergedJaegerThriftCompactConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:6831") .Values.traces.jaeger.thriftCompact.receiverConfig }}
            {{- toYaml $mergedJaegerThriftCompactConfig | nindent 10 }}
          {{- end }}
          {{- if .Values.traces.jaeger.thriftBinary.enabled }}
          thrift_binary:
            {{- $mergedJaegerThriftBinaryConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:6832") .Values.traces.jaeger.thriftBinary.receiverConfig }}
            {{- toYaml $mergedJaegerThriftBinaryConfig | nindent 10 }}
          {{- end }}
          {{- if .Values.traces.jaeger.thriftHttp.enabled }}
          thrift_http:
            {{- $mergedJaegerThriftHttpConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:14268") .Values.traces.jaeger.thriftHttp.receiverConfig }}
            {{- toYaml $mergedJaegerThriftHttpConfig | nindent 10 }}
          {{- end }}
          {{- if .Values.traces.jaeger.grpc.enabled }}
          grpc:
            {{- $mergedJaegerGrpcConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:14250") .Values.traces.jaeger.grpc.receiverConfig }}
            {{- toYaml $mergedJaegerGrpcConfig | nindent 10 }}
          {{- end }}
      {{- end }}
      {{- if .Values.traces.zipkin.enabled }}
      zipkin:
        {{- $mergedZipkinReceiverConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:9411") .Values.traces.zipkin.receiverConfig }}
        {{- toYaml $mergedZipkinReceiverConfig | nindent 6 }}
      {{- end }}
      {{- if or (.Values.traces.otlp.http.enabled) (.Values.traces.otlp.grpc.enabled) }}
      otlp:
        protocols:
          {{- if .Values.traces.otlp.http.enabled }}
          http:
            {{- $mergedOtlpHttpReceiverConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:4318") .Values.traces.otlp.http.receiverConfig }}
            {{- toYaml $mergedOtlpHttpReceiverConfig | nindent 10 }}
          {{- end }}
          {{- if .Values.traces.otlp.grpc.enabled }}
          grpc:
            {{- $mergedOtlpGrpcReceiverConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:4317") .Values.traces.otlp.grpc.receiverConfig }}
            {{- toYaml $mergedOtlpGrpcReceiverConfig | nindent 10 }}
          {{- end }}
      {{- end }}
      {{- if .Values.traces.opencensus.enabled }}
      opencensus:
        {{- $mergedOpencensusReceiverConfig := mustMergeOverwrite (dict "endpoint" "0.0.0.0:55678") .Values.traces.opencensus.receiverConfig }}
        {{- toYaml $mergedOpencensusReceiverConfig | nindent 6 }}
      {{- end }}
      {{- if .Values.traces.kafka }}
      kafka:
        {{- toYaml .Values.traces.kafka | nindent 6 }}
      {{- end }}
    {{- if or .Values.distributor.config.log_received_traces .Values.distributor.config.log_received_spans.enabled }}
    log_received_spans:
      enabled: {{ or .Values.distributor.config.log_received_traces .Values.distributor.config.log_received_spans.enabled }}
      include_all_attributes: {{ .Values.distributor.config.log_received_spans.include_all_attributes }}
      filter_by_status_error: {{ .Values.distributor.config.log_received_spans.filter_by_status_error }}
    {{- end }}
    {{- if .Values.distributor.config.extend_writes }}
    extend_writes: {{ .Values.distributor.config.extend_writes }}
    {{- end }}
  querier:
    frontend_worker:
      frontend_address: {{ include "tempo.resourceName" (dict "ctx" . "component" "query-frontend-discovery") }}:9095
      {{- if .Values.querier.config.frontend_worker.grpc_client_config }}
      grpc_client_config:
        {{- toYaml .Values.querier.config.frontend_worker.grpc_client_config | nindent 6 }}
      {{- end }}
    trace_by_id:
      query_timeout: {{ .Values.querier.config.trace_by_id.query_timeout }}
    search:
      external_endpoints: {{- toYaml .Values.querier.config.search.external_endpoints | nindent 6 }}
      query_timeout: {{ .Values.querier.config.search.query_timeout }}
      prefer_self: {{ .Values.querier.config.search.prefer_self }}
      external_hedge_requests_at: {{ .Values.querier.config.search.external_hedge_requests_at }}
      external_hedge_requests_up_to: {{ .Values.querier.config.search.external_hedge_requests_up_to }}
    max_concurrent_queries: {{ .Values.querier.config.max_concurrent_queries }}
  query_frontend:
    max_retries: {{ .Values.queryFrontend.config.max_retries }}
    search:
      target_bytes_per_job: {{ .Values.queryFrontend.config.search.target_bytes_per_job }}
      concurrent_jobs: {{ .Values.queryFrontend.config.search.concurrent_jobs }}
    trace_by_id:
      query_shards: {{ .Values.queryFrontend.config.trace_by_id.query_shards }}
      hedge_requests_at: {{ .Values.queryFrontend.config.trace_by_id.hedge_requests_at }}
      hedge_requests_up_to: {{ .Values.queryFrontend.config.trace_by_id.hedge_requests_up_to }}

  ingester:
    lifecycler:
      ring:
        replication_factor: {{ .Values.ingester.config.replication_factor }}
        kvstore:
          store: etcd
          prefix: tempo-ingester/
          etcd:
            endpoints: [loki-etcd.loki.svc.cluster.local:2379]
            dial_timeout: 10s
            max_retries: 10
            tls_enabled: false
            username: "root"
            password: "BigESi7UYRbG41DG"
      tokens_file_path: /var/tempo/tokens.json
    {{- if .Values.ingester.config.trace_idle_period }}
    trace_idle_period: {{ .Values.ingester.config.trace_idle_period }}
    {{- end }}
    {{- if .Values.ingester.config.flush_check_period }}
    flush_check_period: {{ .Values.ingester.config.flush_check_period }}
    {{- end }}
    {{- if .Values.ingester.config.max_block_bytes }}
    max_block_bytes: {{ .Values.ingester.config.max_block_bytes }}
    {{- end }}
    {{- if .Values.ingester.config.max_block_duration }}
    max_block_duration: {{ .Values.ingester.config.max_block_duration }}
    {{- end }}
    {{- if .Values.ingester.config.complete_block_timeout }}
    complete_block_timeout: {{ .Values.ingester.config.complete_block_timeout }}
    {{- end }}
  overrides:
    {{- toYaml .Values.global_overrides | nindent 2 }}
    {{- if .Values.metricsGenerator.enabled }}
    metrics_generator_processors:
    {{- range .Values.global_overrides.metrics_generator_processors }}
    - {{ . }}
    {{- end }}
    {{- end }}
  server:
    http_listen_port: {{ .Values.server.httpListenPort }}
    log_level: {{ .Values.server.logLevel }}
    log_format: {{ .Values.server.logFormat }}
    grpc_server_max_recv_msg_size: {{ .Values.server.grpc_server_max_recv_msg_size }}
    grpc_server_max_send_msg_size: {{ .Values.server.grpc_server_max_send_msg_size }}
    http_server_read_timeout: {{ .Values.server.http_server_read_timeout }}
    http_server_write_timeout: {{ .Values.server.http_server_write_timeout }}
  storage:
    trace:
      block:
        version: {{.Values.storage.trace.block.version}}
      backend: {{.Values.storage.trace.backend}}
      {{- if eq .Values.storage.trace.backend "s3"}}
      s3:
        {{- toYaml .Values.storage.trace.s3 | nindent 6}}
      {{- end }}
      blocklist_poll: 5m
      local:
        path: /var/tempo/traces
      wal:
        path: /var/tempo/wal
      cache: redis
      redis:
        endpoint: "172.16.250.225:26383,172.16.250.226:26383,172.16.250.227:26383"
        master_name: "mymaster"
        timeout: 500ms
        password: "eeoredis6388"
        expiration: 24h

server:
  httpListenPort: 3100
  logLevel: info
  logFormat: logfmt
  grpc_server_max_recv_msg_size: 8388608
  grpc_server_max_send_msg_size: 8388608
  http_server_read_timeout: 30s
  http_server_write_timeout: 30s

storage:
  trace:
    block:
      version: vParquet2
    backend: s3
    s3:
      bucket: ""
      endpoint: "obs.cn-north-4.myhuaweicloud.com"
      region: "north-4"
      access_key: ""
      secret_key: ""
      insecure: false
      tls_insecure_skip_verify: false
  admin:
    backend: s3

global_overrides:
#  per_tenant_override_config: /conf/overrides.yaml
  max_bytes_per_trace: 2000000
  max_traces_per_user: 20000
  metrics_generator_processors: []

metaMonitoring:
  serviceMonitor:
    enabled: true
    namespace: monitoring
    namespaceSelector: {}
    annotations: {}
    labels: {}
    interval: null
    scrapeTimeout: null
    relabelings: []
    metricRelabelings: []
    scheme: http
    tlsConfig: null

  grafanaAgent:
    enabled: false

    installOperator: false

    logs:
      remote:
        url: ''

        auth:
          tenantId: ''

          username: ''

          passwordSecretName: ''
          passwordSecretKey: ''

      additionalClientConfigs: []

    metrics:
      remote:
        url: ''

        headers: {}
        auth:
          username: ''

          passwordSecretName: ''
          passwordSecretKey: ''

      additionalRemoteWriteConfigs: []

      scrapeK8s:
        enabled: true

        kubeStateMetrics:
          namespace: kube-system
          labelSelectors:
            app.kubernetes.io/name: kube-state-metrics

    namespace: ''

    labels: {}

    annotations: {}

prometheusRule:
  enabled: true
  namespace: null
  annotations: {}
  labels: {}
  groups: []

gateway:
  enabled: true
  replicas: 1
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage:
  verboseLogging: true
  image:
    repository: nginxinc/nginx-unprivileged
    tag: 1.19-alpine
    pullPolicy: IfNotPresent
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumes: []
  extraVolumeMounts: []
  terminationGracePeriodSeconds: 30
  service:
    port: 80
    type: ClusterIP
    clusterIP: null
    nodePort: null
    loadBalancerIP: null
    annotations: {}
    labels: {}
    additionalPorts: {}
  ingress:
    enabled: false
    annotations: {}
    hosts:
      - host: gateway.tempo.example.com
        paths:
          - path: /
    tls:
      - secretName: tempo-gateway-tls
        hosts:
          - gateway.tempo.example.com
  basicAuth:
    enabled: false
    username: null
    password: null
    htpasswd: >-
      {{ htpasswd (required "'gateway.basicAuth.username' is required" .Values.gateway.basicAuth.username) (required "'gateway.basicAuth.password' is required" .Values.gateway.basicAuth.password) }}
    existingSecret: null
  readinessProbe:
    httpGet:
      path: /
      port: http-metrics
    initialDelaySeconds: 15
    timeoutSeconds: 1
  nginxConfig:
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    serverSnippet: ''
    httpSnippet: ''
    resolver: ''
    file: |
      error_log  /dev/stderr;
      pid        /tmp/nginx.pid;
      worker_rlimit_nofile 8192;

      events {
      }

      http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path       /tmp/proxy_temp_path;
        fastcgi_temp_path     /tmp/fastcgi_temp;
        uwsgi_temp_path       /tmp/uwsgi_temp;
        scgi_temp_path        /tmp/scgi_temp;

        proxy_http_version    1.1;

        default_type application/octet-stream;
        log_format   {{ .Values.gateway.nginxConfig.logFormat }}

        {{- if .Values.gateway.verboseLogging }}
        access_log   /dev/stderr  main;
        {{- else }}

        map $status $loggable {
          ~^[23]  0;
          default 1;
        }
        access_log   /dev/stderr  main  if=$loggable;
        {{- end }}

        sendfile     on;
        tcp_nopush   on;
        {{- if .Values.gateway.nginxConfig.resolver }}
        resolver {{ .Values.gateway.nginxConfig.resolver }};
        {{- else }}
        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};
        {{- end }}

        {{- with .Values.gateway.nginxConfig.httpSnippet }}
        {{ . | nindent 2 }}
        {{- end }}

        server {
          listen             8080;

          {{- if .Values.gateway.basicAuth.enabled }}
          auth_basic           "Tempo";
          auth_basic_user_file /etc/nginx/secrets/.htpasswd;
          {{- end }}

          location = / {
            return 200 'OK';
            auth_basic off;
          }

          location = /jaeger/api/traces {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "distributor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:14268/api/traces;
          }

          location = /zipkin/spans {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "distributor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:9411/spans;
          }

          location = /otlp/v1/traces {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "distributor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:4318/v1/traces;
          }

          location ^~ /api {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "query-frontend") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location = /flush {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "ingester") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location = /shutdown {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "ingester") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location = /distributor/ring {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "distributor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location = /ingester/ring {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "distributor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          location = /compactor/ring {
            proxy_pass       http://{{ include "tempo.resourceName" (dict "ctx" . "component" "compactor") }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:3100$request_uri;
          }

          {{- with .Values.gateway.nginxConfig.serverSnippet }}
          {{ . | nindent 4 }}
          {{- end }}
        }
      }

enterprise:
  enabled: false

license:
  contents: 'NOTAVALIDLICENSE'
  external: false
  secretName: '{{ include "tempo.resourceName" (dict "ctx" . "component" "license") }}'

tokengenJob:
  enable: true
  extraArgs: {}
  env: []
  extraEnvFrom: []
  annotations: {}
  initContainers: []
  containerSecurityContext:
    readOnlyRootFilesystem: true
memcached:
  enabled: false
